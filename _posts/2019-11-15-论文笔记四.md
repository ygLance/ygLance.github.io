---
published: true
title: 对话系统论文笔记四：主题
category: Dialogue System
tags: 
  - DL
  - DS
  - paper reading
layout: post
---

2019.11.15 更新 Target-Guided Open-Domain Conversation

2019.11.15 更新 Proactive Human-Machine Conversation with Explicit Conversation Goals

2019.11.15 更新 Proactive Knowledge-Goals Dialogue System Based on Pointer Network

2019.11.25 更新 Chat More If You Like: Dynamic Cue Words Planning to Flow Longer Conversations

2019.12.2 更新 Topic Aware Neural Response Generation

2019.12.3 重看并更新 Chat More If You Like: Dynamic Cue Words Planning to Flow Longer Conversations

2019.12.3 更新 Chat More: Deepening and Widening the Chatting Topic via A Deep Model



# Target-Guided Open-Domain Conversation

ACL 2019

## 总结

这篇文章想要解决的问题是：在对话的过程中由一个随机的topic(文章里简单把key word当作topic)逐渐转到一个给定的topic (target)。如下图所示

![target-guied](https://github.com/Logos23333/Logos23333.github.io/blob/master/_posts/image/paper/target-guided.png?raw=true)

在对话开始时agent有一个target topic `e-books`,而user最开始聊的是`tired`，在对话过程中，topic逐渐转移成`e-books`。

文章的模型非常简单，整个模型分成三个部分：

- keyword predictor: 这个module用监督学习的方法预测下一句的key word

- keyword selection: 进一步在上一个module得到的candicates里选择一个key word，此key word与target的相似度需要比原来的高，这样可以保证key word最后一定会收敛到target (cosine similarity)

- reponse retrieval: 用检索式的方法选择一个与key word最相关的response



# Proactive Human-Machine Conversation with Explicit Conversation Goals

ACL 2019

## 总结

这篇文章定义的问题是，给定context $X$，dialogue goal $G$ = [$start, topic\_a, topic\_b$]，related knowledge $K$，生成能完成dialogue goal及包含相关知识并与上下文有关的response $Y$。针对这个新问题，文章提出了一个新的数据集，这个数据集的每一个dialogue都由一个leader和follower人工生成，leader负责引导topic，而follower只作response。文章还针对此问题提出了模型，将knowledge和 goal等隐式编码，再经过几层处理最后得到response。看了文章我最大的疑惑就是，为什么将 dialogue goal隐式编码就能够进行话题的转移呢？在它的model里，dialogue goal甚至是和knowleage等一起编码的，很不可解释。有没有这么一种可能，这个user goal完全没有作用，只是因为这个数据集足够好，实验的结果才比较好看？相对来说，我很不喜欢这篇论文，不客气的讲，完全是拿钱堆出来的论文，对于读者而言没有启发。

# Proactive Knowledge-Goals Dialogue System Based on Pointer Network

NLPCC 2019

## 总结

这篇文章应该是打了百度的比赛，然后把自己比赛的模型拿出来投稿，但是文章有很多错漏，前后逻辑也有不通顺之处，数学符号不规范，最重要的是它motivation有讲如何引导topic，但是在model部分完全就是把自己的model罗列出来，根本没有进行解释，也没有与motivation形成对应关系。

无语。

# Chat More If You Like: Dynamic Cue Words Planning to Flow Longer Conversations

## 总结

2018年11月就挂在arxiv上的工作。这个工作也是做topic motivation，但是并没有提出一个target topic，而是说在当前topic结束的时候如何转向一个更好的topic，这里有三个问题，一是如何判断当前topic该结束了，二是用什么指标来说明转移后的topic非常合适，三是用什么数据集做实验。但文章通篇没有提到当前topic的*结束标志*，用来评价response的指标也都还是那几个，没什么有用的信息。来讲一讲模型部分，整个模型就分成两个部分，如何选择cue word（其实也就是Keyword）,如何将cue word引入生成response，关于后者，文章采用了一般的做法，也就是seq2seq，将cue word的embedding隐式编码，关于前者，作者用了一个RL的框架用于选择更好的cue word，关于RL其实只需要看它的reward部分，模型用了两个指标来计算Reward，$effectiveness$和$relevance$，前者计算cue word跟当前utterance和生成utterance的cos相似度，后者计算生成的utterance和context的相关度。

不过这是我看到的第一篇用RL做topic transition的工作，还是有可以借鉴地方，在做RL之前，作者先用监督学习预训练了模型，在做RL时，当T turns对话结束视为一次sample。挺像复现一下看看代码的，可是源码并没有公布。文章中有些地方的表述怪怪的。

# Topic Aware Neural Response Generation

AAAI 2017

## 总结

17年的工作，最近在做跟topic相关的工作，这篇是必须要去看看的.这篇工作首次提出了在对话中的topic相关概念，作者认为在对话中，人们先是形成了topic-related的concepts，进而由这些concepts组织语言形成回复，所以在回复中引入topic information（作为先验知识）能提高回复质量以及回复能包含更多的信息。具体的做法就是先由message$X$生成topic word，再根据此topic word选择n个word（文章中似乎没提是怎么选择的，很模糊），引入一个attention机制将这n个word和$X$一起输入，得到回复。

# Chat More: Deepening and Widening the Chatting Topic via A Deep Model

SIGIR 2018

## 总结

这篇文章的标题就让我很感兴趣，读过之后略有失望。作者认为，要deepening topic就是从context中选出一些词，再将这些词和context一起encode，要widening topic就是选出一些和topic相关但是并未出现在context中的词，同样的，将这些词encode，再将context, selected words, predicted words一起通过各种attention拼接，通过一个decoder得到response。这篇文章并没有说清楚什么是deeping and widening topic，并且在训练的时候，selected words是从context中选出来的，predicted words是从response中选出来的，这样真的能deeping and widening topic吗？本质上还是去拟合数据集。文章还提到一点说，context中不超过45.2%的words是对生成回复有帮助的，也就是说context大部分的内容是noise？有何依据呢？我在文章中似乎找不到。